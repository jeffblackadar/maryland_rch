{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3-run-predictions","provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1607271142338}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmPZ7xTnE5Tq","executionInfo":{"status":"ok","timestamp":1634998443939,"user_tz":240,"elapsed":20808,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"2b4d6dd9-95e2-41cd-fb2e-403dd85b948a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OyFqwMTVowF","executionInfo":{"status":"ok","timestamp":1634945410851,"user_tz":240,"elapsed":332,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"33ceeaa2-a570-441d-ef75-e28010fcd5dd"},"source":["%cd /content/drive/MyDrive/crane_maryland\n","!mkdir /content/drive/MyDrive/crane_maryland/mask-rcnn-repository"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/crane_maryland\n"]}]},{"cell_type":"code","metadata":{"id":"uFz9hNjyWtT0","executionInfo":{"status":"ok","timestamp":1634945668997,"user_tz":240,"elapsed":334,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}}},"source":["!mkdir /content/drive/MyDrive/crane_maryland/predictions"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"J1jByQzbf9Sk","executionInfo":{"status":"ok","timestamp":1634998556499,"user_tz":240,"elapsed":169,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}}},"source":["!mkdir /content/drive/MyDrive/crane_maryland/polys"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySDkvobMEyxu","executionInfo":{"status":"ok","timestamp":1634945443385,"user_tz":240,"elapsed":155,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"a0856938-f159-44b6-9d71-6bc99e71c798"},"source":["%cd /content/drive/MyDrive/crane_maryland/mask-rcnn-repository"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/crane_maryland/mask-rcnn-repository\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qu6MXd3gFcna","executionInfo":{"status":"ok","timestamp":1634945458092,"user_tz":240,"elapsed":12245,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"0ceb59a4-5b0b-46f3-99a7-a6b6d570910a"},"source":["!git clone https://github.com/matterport/Mask_RCNN.git\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Mask_RCNN'...\n","remote: Enumerating objects: 956, done.\u001b[K\n","remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n","Receiving objects: 100% (956/956), 125.23 MiB | 17.52 MiB/s, done.\n","Resolving deltas: 100% (562/562), done.\n","Checking out files: 100% (76/76), done.\n"]}]},{"cell_type":"code","metadata":{"id":"KhFyZXpJH7xH"},"source":["#Thanks to https://emadehsan.com/p/object-detection\n","%cd /content/drive/MyDrive/crane_maryland/mask-rcnn-repository/Mask_RCNN\n","!python setup.py install "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"mctx_SheYWZF","executionInfo":{"status":"ok","timestamp":1634946093642,"user_tz":240,"elapsed":4733,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"bc4732d9-3866-42e6-d75b-5fdf6f7e27a9"},"source":["!pip install 'h5py<3.0.0'"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting h5py<3.0.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.15.0)\n","Installing collected packages: h5py\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","Successfully installed h5py-2.10.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["h5py"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"wC-ajugrIXgs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634946342759,"user_tz":240,"elapsed":372,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"b1961ff1-2acc-441a-828f-3a695b4c668e"},"source":["import os\n","# Root directory of the project\n","ROOT_DIR = os.path.abspath(\"./content/drive/MyDrive/crane_maryland/mask-rcnn-repository/Mask_RCNN\")\n","\n","# Import Mask RCNN\n","!sys.path.append(ROOT_DIR)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: -c: line 0: syntax error near unexpected token `ROOT_DIR'\n","/bin/bash: -c: line 0: `sys.path.append(ROOT_DIR)'\n"]}]},{"cell_type":"code","metadata":{"id":"qtvaW1STHCsI","executionInfo":{"status":"ok","timestamp":1634946345167,"user_tz":240,"elapsed":140,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}}},"source":["# Write Annot\n","def write_annot(obj_type, obj_annots_dir, obj_f_num, org_f_name, org_f_path,org_f_width,org_f_height,org_f_depth, refPts, scores):\n","    # With credit to: \n","    # https://www.geeksforgeeks.org/reading-writing-text-files-python/\n","    annot_file_path = obj_annots_dir+obj_f_num+'.xml'\n","    annot_file = open(annot_file_path,\"w\") \n","\n","    annot_file.write(\"<annotation>\\n\") \n","    annot_file.write(\"\t<folder>\"+obj_type+\"</folder>\\n\") \n","    annot_file.write(\"\t<filename>\"+org_f_name+\"</filename>\\n\") \n","    annot_file.write(\"\t<path>\"+org_f_path+\"</path>\\n\") \n","    annot_file.write(\"\t<source>\\n\") \n","    annot_file.write(\"\t\t<database>Muhlenberg_charcoal_hearths</database>\\n\") \n","    annot_file.write(\"\t</source>\\n\") \n","    annot_file.write(\"\t<size>\\n\") \n","    annot_file.write(\"\t\t<width>\"+str(org_f_width)+\"</width>\\n\") \n","    annot_file.write(\"\t\t<height>\"+str(org_f_height)+\"</height>\\n\") \n","    annot_file.write(\"\t\t<depth>\"+str(org_f_depth)+\"</depth>\\n\") \n","    annot_file.write(\"\t</size>\\n\")\n","    annot_file.write(\"\t<!-- <object_present>0 = the object is not present in the image. 1 = it is -->\\n\")\n","    annot_file.write(\"\t<object_present>0</object_present>\\n\")    \n","    for ocn in range(0,len(refPts)):\n","        refPt = refPts[ocn]\n","        refPtMin = refPt[0]\n","        refPtMax = refPt[1]\n","        annot_file.write(\"\t<object>\\n\") \n","        annot_file.write(\"\t\t<name>\"+obj_type+\"</name>\\n\") \n","        annot_file.write(\"\t\t<number>\"+str(ocn)+\"</number>\\n\") \n","        annot_file.write(\"\t\t<score>\"+str(scores[ocn])+\"</score>\\n\")\n","        annot_file.write(\"\t\t<correct>0</correct>\\n\")\n","        annot_file.write(\"\t\t<bndbox>\\n\") \n","        annot_file.write(\"\t\t\t<xmin>\"+str(refPtMin[0])+\"</xmin>\\n\") \n","        annot_file.write(\"\t\t\t<ymin>\"+str(refPtMin[1])+\"</ymin>\\n\") \n","        annot_file.write(\"\t\t\t<xmax>\"+str(refPtMax[0])+\"</xmax>\\n\") \n","        annot_file.write(\"\t\t\t<ymax>\"+str(refPtMax[1])+\"</ymax>\\n\") \n","        annot_file.write(\"\t\t</bndbox>\\n\") \n","        annot_file.write(\"\t</object>\\n\") \n","    annot_file.write(\"</annotation>\\n\") \n","    annot_file.close()\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"3MRtgvq4VV1i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634946353047,"user_tz":240,"elapsed":1915,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"d3923e47-90bb-46bb-b283-0d409698f83d"},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","import keras\n","import skimage\n","print(tf.__version__)\n","print(keras.__version__) # == 2.2.4\n","#Tensorflow-gpu version #== 1.12.0\n","print(skimage.__version__) # == 0.14.2\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n","1.15.2\n","2.3.1\n","0.16.2\n"]},{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}]},{"cell_type":"code","metadata":{"id":"-ct1EziNGCDp"},"source":["# Predict it for all the images\n","# Run Predict Config and Write Annot before running this cell.\n","cfg_name='cfg20200826T2315'\n","model_epoch='0016'\n","object_type = \"charcoal_hearth_hill\"\n","\n","print(\"cfg_name:\",cfg_name)\n","\n","#For all of the jpegs, run prediction\n","\n","#images_dir\n","# Run on all images - produce results for analysis.\n","images_dir = '/content/drive/MyDrive/crane_maryland/tif/tif_tiles/jpgs'\n","\n","import os\n","from os import listdir\n","import skimage\n","import cv2\n","from xml.etree import ElementTree\n","from numpy import zeros\n","from numpy import asarray\n","from mrcnn.utils import Dataset\n","from mrcnn.visualize import display_instances\n","from mrcnn.utils import extract_bboxes\n","from mrcnn.config import Config\n","import mrcnn.model as modellib\n","\n","# define the prediction configuration\n","class PredictionConfig(Config):\n","\t# define the name of the configuration\n","\tNAME = object_type+\"_cfg\" \n","\t# number of classes (background + class (charcoal hearth))\n","\tNUM_CLASSES = 1 + 1\n","\t# simplify GPU config\n","\tGPU_COUNT = 1\n","\tIMAGES_PER_GPU = 1\n","\n","# create config\n","cfg = PredictionConfig()\n","# define the model\n","print(\"hi\")\n","model = modellib.MaskRCNN(mode='inference', model_dir='/content/drive/MyDrive/MaskCNNhearths/code_and_working_data/charcoal_hearth_hill/model/', config=cfg)\n","print(\"hi2\")\n","# load model weights\n","model_path = '/content/drive/MyDrive/MaskCNNhearths/code_and_working_data/charcoal_hearth_hill/model/charcoal_hearth_hill_cfg20200826T2315/mask_rcnn_charcoal_hearth_hill_cfg_0016.h5'\n","#model_path = '/home/student/charcoal_hearth_hill/model/'+object_type+'_'+cfg_name+'/mask_rcnn_'+object_type+'_cfg_'+model_epoch+'.h5'\n","model.load_weights(model_path, by_name=True)\n","\n","image_prediction_folder = '/content/drive/MyDrive/crane_maryland/predictions/'+cfg_name\n","\n","image_for_prediction_folder = images_dir\n","\n","if not os.path.exists(image_prediction_folder):\n","    os.mkdir(image_prediction_folder)\n","image_prediction_folder = image_prediction_folder+'/unknown/'\n","if not os.path.exists(image_prediction_folder):\n","    os.mkdir(image_prediction_folder)\n","    \n","    \n","#Store the results in XML    \n","class_names = [object_type,object_type,]\n","\n","\n","# find all images\n","for filename in listdir(images_dir):\n","    # extract image id\n","    image_id = filename[:-4]\n","    img_path = os.path.join(images_dir, filename)\n","    #ann_path = annotations_dir + image_id + '.xml'\n","    #print(image_id,img_path,ann_path)\n","    print(image_id,img_path)\n","    \n","    image = cv2.imread(img_path)\n","    #image = skimage.io.imread(os.path.join(image_for_prediction_folder, test_file_names[cn]))\n","    #print(\"shape:\", image.shape)\n","    # Run detection\n","\n","    results = model.detect([image], verbose=1)\n","    # Visualize results\n","    r = results[0]\n","    #print(r['rois'], class_names, r['scores'])\n","    #print(r['rois'][1],r['rois'][1][0],r['rois'][1][1],r['rois'][1][2],r['rois'][1][3])\n","    #image2= display_instances(image, r['rois'], r['masks'], r['class_ids'], \n","    #class_names, r['scores'])\n","    obj_f_num = image_id\n","    refPts = []\n","    \n","    for rcn in range(0,len(r['rois'])):\n","        refPt = []\n","        refPtM = []\n","        refPtM.append(r['rois'][rcn][1])\n","        refPtM.append(r['rois'][rcn][0])\n","        refPt.append(refPtM)\n","        refPtM = []\n","        refPtM.append(r['rois'][rcn][3])\n","        refPtM.append(r['rois'][rcn][2])\n","        refPt.append(refPtM)\n","        refPts.append(refPt)\n","        #print(refPts)\n","    write_annot(class_names[0], image_prediction_folder, obj_f_num, filename, image_for_prediction_folder,image.shape[1],image.shape[0],image.shape[2], refPts,r['scores'])\n","print(\"The results are in: \"+image_prediction_folder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aytAZVFHi8z3"},"source":["import os\n","from os import listdir\n","import cv2\n","import skimage\n","from xml.etree import ElementTree\n","from numpy import zeros\n","from numpy import asarray\n","from google.colab.patches import cv2_imshow\n","from matplotlib import pyplot\n","from matplotlib.pyplot import figure\n","\n","#coordinate = \"0106\"\n","#training_image = '/content/drive/MyDrive/crane_ane/data/images/jpgs/401'+coordinate +'.jpg'\n","#prediction_annot_file_path = '/content/drive/MyDrive/MaskCNNhearths/code_and_working_data/charcoal_hearth_hill/predictions/cfg20200826T2315/unknown/401'+coordinate +'.xml'\n","\n","prediction_image_folder = '/content/drive/MyDrive/crane_maryland/tif/tif_tiles/jpgs/'\n","prediction_annot_folder = '/content/drive/MyDrive/crane_maryland/predictions/cfg20200826T2315/unknown'\n","\n","training_annot_file_path = \"\"\n","\n","font = cv2.FONT_HERSHEY_SIMPLEX \n","font_scale = 1\n","font_color = (0, 200, 0) \n","font_thickness = 2\n","\n","for prediction_image in listdir(prediction_image_folder):\n","    print(prediction_image)\n","    annotation_file = prediction_image[:-4]+\".xml\"\n","    image = cv2.imread(os.path.join(prediction_image_folder,prediction_image))\n","    print(image.shape)\n","    prediction_annot_file_path = os.path.join(prediction_annot_folder,annotation_file)\n","\n","    overlay = image.copy()\n","    output = image.copy()\n","    #cv2_imshow(output)    \n","    font_color = (255, 0, 255)\n","    font_scale = .6\n","    font_thickness = 1\n","\n","    print(prediction_annot_file_path)\n","    if(os.path.exists(prediction_annot_file_path)):\n","        tree_train = ElementTree.parse(prediction_annot_file_path)\n","        root_train = tree_train.getroot()\n","        for obj in root_train.findall('./object'):\n","            box = obj.find('bndbox')\n","            xmin = int(box.find('xmin').text)\n","            ymin = int(box.find('ymin').text)\n","            xmax = int(box.find('xmax').text)\n","            ymax = int(box.find('ymax').text)\n","            box_num = str(obj.find('number').text)\n","            score = float(obj.find('score').text)\n","            if(ymin>ymax):\n","                ytemp = ymin\n","                ymin = ymax\n","                ymax=ytemp\n","            if(xmin>xmax):\n","                xtemp = xmin\n","                xmin = xmax\n","                xmax=xtemp            \n","            coors = [xmin, ymin, xmax, ymax]\n","            crop_output = output[ymin:ymax, xmin:xmax]\n","        \n","            cv2.rectangle(output, (xmin, ymin), (xmax, ymax),(255, 0, 255), 2)\n","            cv2.putText(output, f'{score:.3f}' , (xmin+0, ymin-17), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n","        print(root_train.findall('./object'))\n","        objs = root_train.findall('./object')\n","        if(len(objs)>0):\n","            cv2_imshow(output)\n","    else:\n","        print(\"No prediction annotation file for this image.  This is likely ok.\")\n","\n","\n","\n","\n","#crop_output = output[ymin:ymax, xmin:xmax]\n","#resized = cv2.resize(output, (64, 30))"],"execution_count":null,"outputs":[]}]}