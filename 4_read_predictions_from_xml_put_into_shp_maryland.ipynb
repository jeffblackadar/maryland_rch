{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"colab":{"name":"4_read_predictions_from_xml_put_into_shp_maryland.ipynb","provenance":[{"file_id":"1PVRwllaR5czZn-GQ5x9c3Vrfl9Y7VbSe","timestamp":1634996536014}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"irj2I2XBAQdg"},"source":["# Read the predictions from the annot xml files and convert them into GIS shapefiles"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oy7ZoaUibOGF","executionInfo":{"status":"ok","timestamp":1635949459477,"user_tz":240,"elapsed":42927,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"b114d5b0-5b4d-468a-8468-6881ea5c68ee"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"MmhL42tDibbC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635949523831,"user_tz":240,"elapsed":7149,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"a637f93d-bcf1-4866-d227-dcb902d1b61a"},"source":["!pip install geopandas"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting geopandas\n","  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 163 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 194 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 204 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 215 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 225 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 256 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 266 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 276 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 317 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 327 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 337 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 348 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 358 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 378 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 399 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 409 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 430 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 440 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 450 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 460 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 471 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 481 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 491 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 501 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 512 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 522 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 532 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 542 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 552 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 563 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 573 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 593 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 604 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 624 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 634 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 645 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 655 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 665 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 675 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 686 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 696 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 706 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 716 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 727 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 737 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 747 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 757 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 768 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 778 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 788 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 798 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 819 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 829 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 839 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 849 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 860 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 870 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 880 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 890 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 901 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 911 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 921 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 931 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 942 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 952 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 962 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 972 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 983 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 993 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0 MB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0 MB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0 MB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0 MB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n","Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.7.1)\n","Collecting pyproj>=2.2.0\n","  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 48.2 MB/s \n","\u001b[?25hCollecting fiona>=1.8\n","  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\n","\u001b[K     |████████████████████████████████| 15.4 MB 79 kB/s \n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.5.30)\n","Collecting munch\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n","Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.2.0)\n","Collecting cligj>=0.5\n","  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n","Collecting click-plugins>=1.0\n","  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2018.9)\n","Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n","Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n"]}]},{"cell_type":"code","metadata":{"id":"dEca295aAQds"},"source":["# cell 2.0 - Run this load these functions\n","def get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,x,y):\n","    # supposing x and y are your pixel coordinate this \n","    # is how to get the coordinate in space.\n","    posX = px_w * x + rot1 * y + xoffset\n","    posY = rot2 * x + px_h * y + yoffset\n","\n","    # shift to the center of the pixel\n","    posX += px_w / 2.0\n","    posY += px_h / 2.0\n","    return posX,posY\n","\n","def get_poly_from_geotif_with_x_y(geotif_fp,minx,miny,maxx,maxy):\n","    ds = gdal.Open(geotif_fp)\n","    # open the dataset and get the geo transform matrix\n","\n","    xoffset, px_w, rot1, yoffset, rot2,px_h = ds.GetGeoTransform()\n","\n","    #print(\"xoffset, px_w, rot1, yoffset, px_h, rot2\",xoffset, px_w, rot1, yoffset, px_h, rot2)\n","    print(\"minx,miny,maxx,maxy\",minx,miny,maxx,maxy)\n","\n","    pos1x,pos1y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,minx,miny)\n","    pos2x,pos2y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,minx,maxy)\n","    pos3x,pos3y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,maxx,maxy)\n","    pos4x,pos4y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,maxx,miny)\n","    coords = [(pos1x,pos1y), (pos2x,pos2y), (pos3x,pos3y), (pos4x,pos4y)]\n","\n","    #print(\"pos\",pos1x,pos1y,pos2x,pos2y,pos3x,pos3y,pos4x,pos4y)\n","    poly = Polygon(coords)\n","    \n","    return poly "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kfwz3_jAQdv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634997803021,"user_tz":240,"elapsed":164,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"7ecd7274-cec7-46b2-ccfe-f5ff109f1609"},"source":["# cell 2.1 - Run this to load a dictionary of files to process\n","# Looping through them repeatedly takes a long time.\n","# Instead, create a dictionary of files indexed by area.  Each entry holds a list of matching files\n","# This makes it easier to process these files by area.\n","\n","import csv\n","from os import listdir\n","import os\n","construction_type = \"charcoal_hearth_hill\"\n","cfg_name = 'cfg20200826T2315'\n","\n","#make a dict of all the areas + pan (or pas)\n","area_crs_dict = {}\n","\"\"\"\n","with open('/home/student/charcoalhearths/data_sheet.csv') as csvfile:\n","    reader = csv.DictReader(csvfile)\n","    for row in reader:\n","        #print(row['Area'])\n","        area=row['Area']\n","        area=\"0\"+area\n","        area=area[-3:]\n","        pan=\"\"\n","        pas=\"\"\n","        pan = row['PAN']\n","        if(pan == \"Y\"):\n","            area_crs_dict[area+'pan'] = []\n","        pas = row['PAS']\n","        if(pas == \"Y\"):\n","\"\"\"\n","area_crs_dict[\"catoctin_1\"] = []\n","\n","# Now that the dictionary is created, add all of the matching files as a list linked to the entry.\n","# This dictionary will be used below.\n","annot_prediction_folder = os.path.join('/content/drive/MyDrive/crane_maryland/predictions/cfg20200826T2315/unknown/')\n","\n","for annot_filename in listdir(annot_prediction_folder):\n","    annot_area = \"catoctin_1\"\n","    print(annot_filename, annot_area)\n","    area_node = area_crs_dict[annot_area]\n","    area_node.append(annot_filename)\n","print(area_crs_dict) "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["r00c00.xml catoctin_1\n","r00c01.xml catoctin_1\n","r00c02.xml catoctin_1\n","r00c03.xml catoctin_1\n","r01c00.xml catoctin_1\n","r01c01.xml catoctin_1\n","r01c02.xml catoctin_1\n","r01c03.xml catoctin_1\n","r02c00.xml catoctin_1\n","r02c01.xml catoctin_1\n","r02c02.xml catoctin_1\n","r02c03.xml catoctin_1\n","r03c00.xml catoctin_1\n","r03c01.xml catoctin_1\n","r03c02.xml catoctin_1\n","r03c03.xml catoctin_1\n","r04c00.xml catoctin_1\n","r04c01.xml catoctin_1\n","r04c02.xml catoctin_1\n","r04c03.xml catoctin_1\n","r05c00.xml catoctin_1\n","r05c01.xml catoctin_1\n","r05c02.xml catoctin_1\n","r05c03.xml catoctin_1\n","r06c00.xml catoctin_1\n","r06c01.xml catoctin_1\n","r06c02.xml catoctin_1\n","r06c03.xml catoctin_1\n","{'catoctin_1': ['r00c00.xml', 'r00c01.xml', 'r00c02.xml', 'r00c03.xml', 'r01c00.xml', 'r01c01.xml', 'r01c02.xml', 'r01c03.xml', 'r02c00.xml', 'r02c01.xml', 'r02c02.xml', 'r02c03.xml', 'r03c00.xml', 'r03c01.xml', 'r03c02.xml', 'r03c03.xml', 'r04c00.xml', 'r04c01.xml', 'r04c02.xml', 'r04c03.xml', 'r05c00.xml', 'r05c01.xml', 'r05c02.xml', 'r05c03.xml', 'r06c00.xml', 'r06c01.xml', 'r06c02.xml', 'r06c03.xml']}\n"]}]},{"cell_type":"code","metadata":{"id":"c4uUVab3AQdw","executionInfo":{"status":"ok","timestamp":1635949533634,"user_tz":240,"elapsed":398,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}}},"source":["# cell 2.2 \n","construction_type = \"charcoal_hearth_hill\"\n","cfg_name = 'cfg20200826T2315'\n","model_epoch='0016'\n","\n","\n","split_tifs_folder = '/content/drive/MyDrive/crane_maryland/tif/tif_tiles/'\n","# display image with masks and bounding boxes\n","from os import listdir\n","\n","\n","from xml.etree import ElementTree\n","#from mrcnn.utils import Dataset\n","#from mrcnn.visualize import display_instances\n","#from mrcnn.utils import extract_bboxes\n","#https://gis.stackexchange.com/questions/92207/split-a-large-geotiff-into-smaller-regions-with-python-and-gdal\n","\n","import numpy\n","from osgeo import gdal, osr\n","import math\n","from itertools import chain\n","import geopandas as gpd\n","from shapely.geometry import Point, Polygon\n","import numpy as np\n","import gdalnumeric\n","import os\n","def put_preds_in_shp(state_area,state_area_num_crs):\n","\n","    pred_polys = gpd.GeoDataFrame()\n","    pred_polys['geometry'] = None\n","    #pred_polys.crs = {'init':'epsg:'+str(state_area_num_crs)}\n","    #pred_polys.crs = (\"EPSG:\" + str(state_area_num_crs))\n","    \n","    # added\n","    #pred_polys.geometry = pred_polys.geometry.to_crs(crs = state_area_num_crs)\n","    #pred_polys.geometry.crs = (\"EPSG:\" + str(state_area_num_crs))\n","    \n","    #pred_polys = pred_polys.crs(epsg=state_area_num_crs)\n","    pred_polys.crs = (\"EPSG:\" + str(state_area_num_crs))\n","    \n","    #pred_polys.geometry = pred_polys.geometry.crs(epsg=state_area_num_crs)\n","    pred_polys.geometry.crs = (\"EPSG:\" + str(state_area_num_crs))\n","    print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","    \n","    # Create an empty geopandas GeoDataFrame\n","    #        tile_boundary_poly = gpd.GeoDataFrame()\n","    #        tile_boundary_poly['geometry'] = None\n","    #        #tile_boundary_poly.crs = {'init':'epsg:4326'}\n","    #        #geotif_crs_4326 = 4326\n","    #        tile_boundary_poly.crs = (\"EPSG:\" + str(geotif_crs))\n","    #        tile_boundary_poly.geometry = tile_boundary_poly.geometry.to_crs(crs=geotif_crs)\n","    #        tile_boundary_poly.to_crs(crs=geotif_crs)\n","    #        tile_boundary_poly = tile_boundary_poly.to_crs(epsg=geotif_crs)\n","    \n","    #pred_polys.crs = {'init':'epsg:32128'}\n","\n","    import cv2\n","\n","    #Store the results in XML    \n","    class_names = construction_type\n","\n","    # find all images\n","\n","    pa = area_crs_dict[str(state_area)]\n","    for annot_filename in pa:\n","    \n","        print(annot_filename)\n","        #process only the files for this state land area, since other areas may not match crs\n","        #if annot_filename.startswith(state_area_num):\n","        tree = ElementTree.parse(annot_prediction_folder+annot_filename)\n","        print(annot_prediction_folder+annot_filename)\n","        #print(tree)\n","        # get the root of the document\n","        root = tree.getroot()\n","        # extract each bounding box\n","    \n","        fn_image = root.find('./filename').text\n","        #object_present = root.find('./object_present').text\n","        fn_base = fn_image[:6]\n","        print(fn_base)\n","        box_num=0\n","        for obj in root.findall('./object'):\n","            score = obj.find('score').text\n","    \n","            box = obj.find('bndbox')\n","            box_num=obj.find('number').text\n","            box_num_pad = \"00\"+str(box_num)\n","            box_num_pad = box_num_pad[-2:]\n","            #boxes_correct[str(box_num)] = correct\n","            xmin = int(box.find('xmin').text)\n","            ymin = int(box.find('ymin').text)\n","            xmax = int(box.find('xmax').text)\n","            ymax = int(box.find('ymax').text)\n","            if(ymin>ymax):\n","                ytemp = ymin\n","                ymin = ymax\n","                ymax=ytemp\n","            if(xmin>xmax):\n","                xtemp = xmin\n","                xmin = xmax\n","                xmax=xtemp            \n","            coors = [xmin, ymin, xmax, ymax]\n","            print(\"score\", score, coors)\n","            print(os.path.join(split_tifs_folder+(fn_base+\".tif\")))\n","            pred_poly = get_poly_from_geotif_with_x_y(os.path.join(split_tifs_folder+(fn_base+\".tif\")),xmin,ymin,xmax,ymax)\n","            new_pp_row = {'id':fn_base+box_num_pad, 'geometry':pred_poly, 'score':score}\n","            pred_polys = pred_polys.append(new_pp_row, ignore_index=True)\n","            print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","            pred_polys.geometry.crs = (\"EPSG:\" + str(state_area_num_crs))\n","            print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","\n","#pred_polys = pred_polys.to_crs(epsg=32128)\n","    outfolder = os.path.join(\"/content/drive/MyDrive/crane_maryland/polys/\", (cfg_name+\"/\"))\n","    if not os.path.exists(outfolder):\n","        os.makedirs(outfolder)\n","    outfp = os.path.join(outfolder,(state_area + \"_predictions.shp\"))\n","                         \n","# Write the data into that Shapefile\n","    if not pred_polys.empty:\n","        print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","        pred_polys.to_file(outfp)\n","        #pred_polys.head()\n","        #pred_polys = pred_polys.to_crs({'init':'epsg:4326'})\n","        #pred_polys = pred_polys.to_crs(epsg = 4326)\n","        crs_4326 = 4326\n","        pred_polys.geometry = pred_polys.geometry.to_crs(crs=crs_4326)\n","        pred_polys.to_crs(crs=crs_4326)\n","        pred_polys = pred_polys.to_crs(epsg=crs_4326)\n","        \n","        #pred_polys = pred_polys.set_crs(epsg = 4326)\n","        #pred_polys.head()\n","        outfp = os.path.join(outfolder,(\"4326_\" + state_area + \"_predictions.shp\"))\n","        # Write the data into that Shapefile\n","        pred_polys.to_file(outfp)\n","\n"," "],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"L32ZeNU6AQdy"},"source":["# cell 2.3 \n","\n","\n","put_preds_in_shp(\"catoctin_1\",26985)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QVxA6t-RAQdz"},"source":["# Convert Polygons to Points and remove Duplicates\n","For each area, load the polygons.\n","Check if any existing points from previous areas processed are inside any of the polygons of this area.\n","If there are \"matches\" (duplicates), the polygons are removed (and stored in a dataframe of duplicates)\n","The left over unique polygons are then processed for their centroids.\n","These points are stored for output and also used to process the polygons for the remaining areas so see if there are duplicates for in the polygons of the remaining areas."]},{"cell_type":"code","metadata":{"id":"7vGTsJWOAQd0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635001138689,"user_tz":240,"elapsed":569,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"519e16f6-9b37-4974-d078-c7d63ef69642"},"source":["import geopandas as gpd\n","import pandas as pd\n","import numpy as np\n","import os\n","def preds_to_points(area, pred_poly_folder, all_pred_points_df, dup_pred_polys_df):\n","    # print(all_pred_points_df.shape)\n","    # 4326_catoctin_1_predictions.shp\n","    print(area)\n","    area_pred_polys_path = os.path.join(pred_poly_folder,(\"4326_\" + area + \"_predictions.shp\"))\n","    print(area_pred_polys_path)\n","    if os.path.exists(area_pred_polys_path):\n","        area_pred_polys = gpd.read_file(area_pred_polys_path)\n","        # selection = pred_data[0:]\n","        # print(list(area_pred_polys))\n","        # print(area_pred_polys.shape)\n","        area_crs = 26985\n","\n","        matched_pred_polys = list()    \n","        area_pred_polys.to_crs(area_crs)\n","        # for pred_poly in area_pred_polys:\n","        for index, row in area_pred_polys.iterrows():\n","            #print(\"row\",row[0],row[1],row[2])\n","            pred_poly = row[2]\n","            # any_points = all_pred_points_df.within(pred_poly.loc[0, 'geometry'])\n","            any_points = all_pred_points_df.within(pred_poly)\n","            #print(\"any_points\",any_points)\n","            if(any(any_points) == True):\n","                # print(\"MATCHES\")\n","                matched_pred_polys.append(str(row[0]))\n","                \n","        # print(matched_pred_polys)\n","        # If there is more than 0 matches, remove them from the dataframe\n","        if(len(matched_pred_polys) > 0 ):\n","            print(\"area_pred_polys len before \",len(area_pred_polys))\n","            for mpp in matched_pred_polys:\n","                index_matches = area_pred_polys[area_pred_polys['id'] == mpp].index\n","                #dup_row = area_pred_polys.loc([area_pred_polys['id'] == mpp]\n","                # get the duplicate row\n","                dup_row = area_pred_polys.loc[area_pred_polys['id'] == mpp]\n","                #print(\"dup_row....\",dup_row,dup_row['id'])\n","                #print(\"index_matches\",index_matches)\n","                #print(\"dup_pred_polys_df len before\",len(dup_pred_polys_df))\n","                # put the duplicate row into a dataframe it can be saved to check it.\n","                dup_pred_polys_df = dup_pred_polys_df.append(dup_row, ignore_index=True)\n","                #print(\"dup_pred_polys_df len after\",len(dup_pred_polys_df))\n","                area_pred_polys.drop(index_matches, inplace = True)\n","            # area_pred_polys.drop(matched_pred_polys)\n","            print(\"area_pred_polys len after \",len(area_pred_polys))\n","            \n","        # Create an empty geopandas GeoDataFrame\n","        area_pred_points_df = gpd.GeoDataFrame()\n","        #area_pred_points_df.crs = {'init':'epsg:' + str(area_crs)}\n","        area_pred_points_df.crs = ('EPSG:' + str(area_crs))\n","        \n","        area_pred_points_df['geometry'] = area_pred_polys.centroid\n","        # make an id\n","        id_list = np.arange(1,len(area_pred_polys.centroid)+1)\n","        # print(id_list)\n","        id_list = [(area + \"-\" + ((\"000\"+str(i))[-4:])) for i in id_list]\n","        # print(id_list)\n","        area_pred_points_df['id'] = id_list\n","        area_pred_points_df['score'] = area_pred_polys['score']\n","        \n","        dataframesList = [all_pred_points_df, area_pred_points_df]\n","        all_pred_points_df = gpd.GeoDataFrame(pd.concat(dataframesList, ignore_index=True), crs=dataframesList[0].crs)\n","        \n","        print(\"Total points area:\", len(all_pred_points_df),\" Total duplicates:\", len(dup_pred_polys_df))\n","        return all_pred_points_df, dup_pred_polys_df\n","    else:\n","        print(\"Total points area:\", len(all_pred_points_df),\" Total duplicates:\", len(dup_pred_polys_df))\n","        return all_pred_points_df, dup_pred_polys_df\n","\n","import csv\n","construction_type = \"charcoal_hearth_hill\"\n","cfg_name = 'cfg20200826T2315'\n","pred_poly_folder = os.path.join(\"/content/drive/MyDrive/crane_maryland/polys/\", (cfg_name + \"/\"))\n","\n","# Create an empty geopandas GeoDataFrame\n","all_pred_points_df = gpd.GeoDataFrame()\n","all_pred_points_df['geometry'] = None\n","all_pred_points_df['id'] = None\n","#all_pred_points_df.crs = {'init':'epsg:4326'}\n","all_pred_points_df.crs = ('EPSG:4326')\n","\n","\n","# Create an empty geopandas GeoDataFrame for duplicates\n","dup_pred_polys_df = gpd.GeoDataFrame()\n","dup_pred_polys_df['geometry'] = None\n","dup_pred_polys_df['id'] = None\n","#dup_pred_polys_df.crs = {'init':'epsg:4326'}\n","dup_pred_polys_df.crs = ('EPSG:4326')\n","\n","\n","all_points_outfp = os.path.join(pred_poly_folder, \"4326_000_hearth_prediction_points.shp\")\n","dup_polys_outfp = os.path.join(pred_poly_folder, \"4326_000_duplicate_hearth_prediction_polys.shp\")\n","\n","\n","all_pred_points_df, dup_pred_polys_df = preds_to_points(\"catoctin_1\", pred_poly_folder, all_pred_points_df, dup_pred_polys_df)\n","\n","# Determine the output path for the Shapefile\n","\n","# Write the data into that Shapefile\n","if not all_pred_points_df.empty:    \n","    all_pred_points_df.to_file(all_points_outfp)\n","    print(\"Total points:\", len(all_pred_points_df))\n","if not dup_pred_polys_df.empty:\n","    dup_pred_polys_df.to_file(dup_polys_outfp)\n","    print(\"Total duplicate polys:\", len(dup_pred_polys_df))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["catoctin_1\n","/content/drive/MyDrive/crane_maryland/polys/cfg20200826T2315/4326_catoctin_1_predictions.shp\n","Total points area: 171  Total duplicates: 0\n","Total points: 171\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n","\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n","\n"]}]}]}