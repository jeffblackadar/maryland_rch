{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"colab":{"name":"4_read_predictions_from_xml_put_into_shp_maryland.ipynb","provenance":[{"file_id":"1PVRwllaR5czZn-GQ5x9c3Vrfl9Y7VbSe","timestamp":1634996536014}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"irj2I2XBAQdg"},"source":["# Read the predictions from the annot xml files and convert them into GIS shapefiles"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oy7ZoaUibOGF","executionInfo":{"status":"ok","timestamp":1634997198635,"user_tz":240,"elapsed":29405,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"deefa452-4337-4c61-82d4-dd40252a649c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"MmhL42tDibbC"},"source":["!pip install geopandas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dEca295aAQds","executionInfo":{"status":"ok","timestamp":1634997162826,"user_tz":240,"elapsed":3,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}}},"source":["# cell 2.0 - Run this load these functions\n","def get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,x,y):\n","    # supposing x and y are your pixel coordinate this \n","    # is how to get the coordinate in space.\n","    posX = px_w * x + rot1 * y + xoffset\n","    posY = rot2 * x + px_h * y + yoffset\n","\n","    # shift to the center of the pixel\n","    posX += px_w / 2.0\n","    posY += px_h / 2.0\n","    return posX,posY\n","\n","def get_poly_from_geotif_with_x_y(geotif_fp,minx,miny,maxx,maxy):\n","    ds = gdal.Open(geotif_fp)\n","    # open the dataset and get the geo transform matrix\n","\n","    xoffset, px_w, rot1, yoffset, rot2,px_h = ds.GetGeoTransform()\n","\n","    #print(\"xoffset, px_w, rot1, yoffset, px_h, rot2\",xoffset, px_w, rot1, yoffset, px_h, rot2)\n","    print(\"minx,miny,maxx,maxy\",minx,miny,maxx,maxy)\n","\n","    pos1x,pos1y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,minx,miny)\n","    pos2x,pos2y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,minx,maxy)\n","    pos3x,pos3y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,maxx,maxy)\n","    pos4x,pos4y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,maxx,miny)\n","    coords = [(pos1x,pos1y), (pos2x,pos2y), (pos3x,pos3y), (pos4x,pos4y)]\n","\n","    #print(\"pos\",pos1x,pos1y,pos2x,pos2y,pos3x,pos3y,pos4x,pos4y)\n","    poly = Polygon(coords)\n","    \n","    return poly "],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kfwz3_jAQdv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634997803021,"user_tz":240,"elapsed":164,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"7ecd7274-cec7-46b2-ccfe-f5ff109f1609"},"source":["# cell 2.1 - Run this to load a dictionary of files to process\n","# Looping through them repeatedly takes a long time.\n","# Instead, create a dictionary of files indexed by area.  Each entry holds a list of matching files\n","# This makes it easier to process these files by area.\n","\n","import csv\n","from os import listdir\n","import os\n","construction_type = \"charcoal_hearth_hill\"\n","cfg_name = 'cfg20200826T2315'\n","\n","#make a dict of all the areas + pan (or pas)\n","area_crs_dict = {}\n","\"\"\"\n","with open('/home/student/charcoalhearths/data_sheet.csv') as csvfile:\n","    reader = csv.DictReader(csvfile)\n","    for row in reader:\n","        #print(row['Area'])\n","        area=row['Area']\n","        area=\"0\"+area\n","        area=area[-3:]\n","        pan=\"\"\n","        pas=\"\"\n","        pan = row['PAN']\n","        if(pan == \"Y\"):\n","            area_crs_dict[area+'pan'] = []\n","        pas = row['PAS']\n","        if(pas == \"Y\"):\n","\"\"\"\n","area_crs_dict[\"catoctin_1\"] = []\n","\n","# Now that the dictionary is created, add all of the matching files as a list linked to the entry.\n","# This dictionary will be used below.\n","annot_prediction_folder = os.path.join('/content/drive/MyDrive/crane_maryland/predictions/cfg20200826T2315/unknown/')\n","\n","for annot_filename in listdir(annot_prediction_folder):\n","    annot_area = \"catoctin_1\"\n","    print(annot_filename, annot_area)\n","    area_node = area_crs_dict[annot_area]\n","    area_node.append(annot_filename)\n","print(area_crs_dict) "],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["r00c00.xml catoctin_1\n","r00c01.xml catoctin_1\n","r00c02.xml catoctin_1\n","r00c03.xml catoctin_1\n","r01c00.xml catoctin_1\n","r01c01.xml catoctin_1\n","r01c02.xml catoctin_1\n","r01c03.xml catoctin_1\n","r02c00.xml catoctin_1\n","r02c01.xml catoctin_1\n","r02c02.xml catoctin_1\n","r02c03.xml catoctin_1\n","r03c00.xml catoctin_1\n","r03c01.xml catoctin_1\n","r03c02.xml catoctin_1\n","r03c03.xml catoctin_1\n","r04c00.xml catoctin_1\n","r04c01.xml catoctin_1\n","r04c02.xml catoctin_1\n","r04c03.xml catoctin_1\n","r05c00.xml catoctin_1\n","r05c01.xml catoctin_1\n","r05c02.xml catoctin_1\n","r05c03.xml catoctin_1\n","r06c00.xml catoctin_1\n","r06c01.xml catoctin_1\n","r06c02.xml catoctin_1\n","r06c03.xml catoctin_1\n","{'catoctin_1': ['r00c00.xml', 'r00c01.xml', 'r00c02.xml', 'r00c03.xml', 'r01c00.xml', 'r01c01.xml', 'r01c02.xml', 'r01c03.xml', 'r02c00.xml', 'r02c01.xml', 'r02c02.xml', 'r02c03.xml', 'r03c00.xml', 'r03c01.xml', 'r03c02.xml', 'r03c03.xml', 'r04c00.xml', 'r04c01.xml', 'r04c02.xml', 'r04c03.xml', 'r05c00.xml', 'r05c01.xml', 'r05c02.xml', 'r05c03.xml', 'r06c00.xml', 'r06c01.xml', 'r06c02.xml', 'r06c03.xml']}\n"]}]},{"cell_type":"code","metadata":{"id":"c4uUVab3AQdw","executionInfo":{"status":"ok","timestamp":1635000050597,"user_tz":240,"elapsed":335,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}}},"source":["# cell 2.2 \n","construction_type = \"charcoal_hearth_hill\"\n","cfg_name = 'cfg20200826T2315'\n","model_epoch='0016'\n","\n","\n","split_tifs_folder = '/content/drive/MyDrive/crane_maryland/tif/tif_tiles/'\n","# display image with masks and bounding boxes\n","from os import listdir\n","\n","\n","from xml.etree import ElementTree\n","#from mrcnn.utils import Dataset\n","#from mrcnn.visualize import display_instances\n","#from mrcnn.utils import extract_bboxes\n","#https://gis.stackexchange.com/questions/92207/split-a-large-geotiff-into-smaller-regions-with-python-and-gdal\n","\n","import numpy\n","from osgeo import gdal, osr\n","import math\n","from itertools import chain\n","import geopandas as gpd\n","from shapely.geometry import Point, Polygon\n","import numpy as np\n","import gdalnumeric\n","import os\n","def put_preds_in_shp(state_area,state_area_num_crs):\n","\n","    pred_polys = gpd.GeoDataFrame()\n","    pred_polys['geometry'] = None\n","    #pred_polys.crs = {'init':'epsg:'+str(state_area_num_crs)}\n","    #pred_polys.crs = (\"EPSG:\" + str(state_area_num_crs))\n","    \n","    # added\n","    #pred_polys.geometry = pred_polys.geometry.to_crs(crs = state_area_num_crs)\n","    #pred_polys.geometry.crs = (\"EPSG:\" + str(state_area_num_crs))\n","    \n","    #pred_polys = pred_polys.crs(epsg=state_area_num_crs)\n","    pred_polys.crs = (\"EPSG:\" + str(state_area_num_crs))\n","    \n","    #pred_polys.geometry = pred_polys.geometry.crs(epsg=state_area_num_crs)\n","    pred_polys.geometry.crs = (\"EPSG:\" + str(state_area_num_crs))\n","    print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","    \n","    # Create an empty geopandas GeoDataFrame\n","    #        tile_boundary_poly = gpd.GeoDataFrame()\n","    #        tile_boundary_poly['geometry'] = None\n","    #        #tile_boundary_poly.crs = {'init':'epsg:4326'}\n","    #        #geotif_crs_4326 = 4326\n","    #        tile_boundary_poly.crs = (\"EPSG:\" + str(geotif_crs))\n","    #        tile_boundary_poly.geometry = tile_boundary_poly.geometry.to_crs(crs=geotif_crs)\n","    #        tile_boundary_poly.to_crs(crs=geotif_crs)\n","    #        tile_boundary_poly = tile_boundary_poly.to_crs(epsg=geotif_crs)\n","    \n","    #pred_polys.crs = {'init':'epsg:32128'}\n","\n","    import cv2\n","\n","    #Store the results in XML    \n","    class_names = construction_type\n","\n","    # find all images\n","\n","    pa = area_crs_dict[str(state_area)]\n","    for annot_filename in pa:\n","    \n","        print(annot_filename)\n","        #process only the files for this state land area, since other areas may not match crs\n","        #if annot_filename.startswith(state_area_num):\n","        tree = ElementTree.parse(annot_prediction_folder+annot_filename)\n","        print(annot_prediction_folder+annot_filename)\n","        #print(tree)\n","        # get the root of the document\n","        root = tree.getroot()\n","        # extract each bounding box\n","    \n","        fn_image = root.find('./filename').text\n","        #object_present = root.find('./object_present').text\n","        fn_base = fn_image[:6]\n","        print(fn_base)\n","        box_num=0\n","        for obj in root.findall('./object'):\n","            score = obj.find('score').text\n","    \n","            box = obj.find('bndbox')\n","            box_num=obj.find('number').text\n","            box_num_pad = \"00\"+str(box_num)\n","            box_num_pad = box_num_pad[-2:]\n","            #boxes_correct[str(box_num)] = correct\n","            xmin = int(box.find('xmin').text)\n","            ymin = int(box.find('ymin').text)\n","            xmax = int(box.find('xmax').text)\n","            ymax = int(box.find('ymax').text)\n","            if(ymin>ymax):\n","                ytemp = ymin\n","                ymin = ymax\n","                ymax=ytemp\n","            if(xmin>xmax):\n","                xtemp = xmin\n","                xmin = xmax\n","                xmax=xtemp            \n","            coors = [xmin, ymin, xmax, ymax]\n","            print(\"score\", score, coors)\n","            print(os.path.join(split_tifs_folder+(fn_base+\".tif\")))\n","            pred_poly = get_poly_from_geotif_with_x_y(os.path.join(split_tifs_folder+(fn_base+\".tif\")),xmin,ymin,xmax,ymax)\n","            new_pp_row = {'id':fn_base+box_num_pad, 'geometry':pred_poly, 'score':score}\n","            pred_polys = pred_polys.append(new_pp_row, ignore_index=True)\n","            print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","            pred_polys.geometry.crs = (\"EPSG:\" + str(state_area_num_crs))\n","            print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","\n","#pred_polys = pred_polys.to_crs(epsg=32128)\n","    outfolder = os.path.join(\"/content/drive/MyDrive/crane_maryland/polys/\", (cfg_name+\"/\"))\n","    if not os.path.exists(outfolder):\n","        os.makedirs(outfolder)\n","    outfp = os.path.join(outfolder,(state_area + \"_predictions.shp\"))\n","                         \n","# Write the data into that Shapefile\n","    if not pred_polys.empty:\n","        print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","        pred_polys.to_file(outfp)\n","        #pred_polys.head()\n","        #pred_polys = pred_polys.to_crs({'init':'epsg:4326'})\n","        #pred_polys = pred_polys.to_crs(epsg = 4326)\n","        crs_4326 = 4326\n","        pred_polys.geometry = pred_polys.geometry.to_crs(crs=crs_4326)\n","        pred_polys.to_crs(crs=crs_4326)\n","        pred_polys = pred_polys.to_crs(epsg=crs_4326)\n","        \n","        #pred_polys = pred_polys.set_crs(epsg = 4326)\n","        #pred_polys.head()\n","        outfp = os.path.join(outfolder,(\"4326_\" + state_area + \"_predictions.shp\"))\n","        # Write the data into that Shapefile\n","        pred_polys.to_file(outfp)\n","\n"," "],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"L32ZeNU6AQdy"},"source":["# cell 2.3 \n","\n","\n","put_preds_in_shp(\"catoctin_1\",26985)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QVxA6t-RAQdz"},"source":["# Convert Polygons to Points and remove Duplicates\n","For each area, load the polygons.\n","Check if any existing points from previous areas processed are inside any of the polygons of this area.\n","If there are \"matches\" (duplicates), the polygons are removed (and stored in a dataframe of duplicates)\n","The left over unique polygons are then processed for their centroids.\n","These points are stored for output and also used to process the polygons for the remaining areas so see if there are duplicates for in the polygons of the remaining areas."]},{"cell_type":"code","metadata":{"id":"7vGTsJWOAQd0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635001138689,"user_tz":240,"elapsed":569,"user":{"displayName":"Jeff Blackadar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwQE5JHLrGNCYuy63hVrIjoYt1pOZq8Ite8hFKnw=s64","userId":"06863186953991085499"}},"outputId":"519e16f6-9b37-4974-d078-c7d63ef69642"},"source":["import geopandas as gpd\n","import pandas as pd\n","import numpy as np\n","import os\n","def preds_to_points(area, pred_poly_folder, all_pred_points_df, dup_pred_polys_df):\n","    # print(all_pred_points_df.shape)\n","    # 4326_catoctin_1_predictions.shp\n","    print(area)\n","    area_pred_polys_path = os.path.join(pred_poly_folder,(\"4326_\" + area + \"_predictions.shp\"))\n","    print(area_pred_polys_path)\n","    if os.path.exists(area_pred_polys_path):\n","        area_pred_polys = gpd.read_file(area_pred_polys_path)\n","        # selection = pred_data[0:]\n","        # print(list(area_pred_polys))\n","        # print(area_pred_polys.shape)\n","        area_crs = 26985\n","\n","        matched_pred_polys = list()    \n","        area_pred_polys.to_crs(area_crs)\n","        # for pred_poly in area_pred_polys:\n","        for index, row in area_pred_polys.iterrows():\n","            #print(\"row\",row[0],row[1],row[2])\n","            pred_poly = row[2]\n","            # any_points = all_pred_points_df.within(pred_poly.loc[0, 'geometry'])\n","            any_points = all_pred_points_df.within(pred_poly)\n","            #print(\"any_points\",any_points)\n","            if(any(any_points) == True):\n","                # print(\"MATCHES\")\n","                matched_pred_polys.append(str(row[0]))\n","                \n","        # print(matched_pred_polys)\n","        # If there is more than 0 matches, remove them from the dataframe\n","        if(len(matched_pred_polys) > 0 ):\n","            print(\"area_pred_polys len before \",len(area_pred_polys))\n","            for mpp in matched_pred_polys:\n","                index_matches = area_pred_polys[area_pred_polys['id'] == mpp].index\n","                #dup_row = area_pred_polys.loc([area_pred_polys['id'] == mpp]\n","                # get the duplicate row\n","                dup_row = area_pred_polys.loc[area_pred_polys['id'] == mpp]\n","                #print(\"dup_row....\",dup_row,dup_row['id'])\n","                #print(\"index_matches\",index_matches)\n","                #print(\"dup_pred_polys_df len before\",len(dup_pred_polys_df))\n","                # put the duplicate row into a dataframe it can be saved to check it.\n","                dup_pred_polys_df = dup_pred_polys_df.append(dup_row, ignore_index=True)\n","                #print(\"dup_pred_polys_df len after\",len(dup_pred_polys_df))\n","                area_pred_polys.drop(index_matches, inplace = True)\n","            # area_pred_polys.drop(matched_pred_polys)\n","            print(\"area_pred_polys len after \",len(area_pred_polys))\n","            \n","        # Create an empty geopandas GeoDataFrame\n","        area_pred_points_df = gpd.GeoDataFrame()\n","        #area_pred_points_df.crs = {'init':'epsg:' + str(area_crs)}\n","        area_pred_points_df.crs = ('EPSG:' + str(area_crs))\n","        \n","        area_pred_points_df['geometry'] = area_pred_polys.centroid\n","        # make an id\n","        id_list = np.arange(1,len(area_pred_polys.centroid)+1)\n","        # print(id_list)\n","        id_list = [(area + \"-\" + ((\"000\"+str(i))[-4:])) for i in id_list]\n","        # print(id_list)\n","        area_pred_points_df['id'] = id_list\n","        area_pred_points_df['score'] = area_pred_polys['score']\n","        \n","        dataframesList = [all_pred_points_df, area_pred_points_df]\n","        all_pred_points_df = gpd.GeoDataFrame(pd.concat(dataframesList, ignore_index=True), crs=dataframesList[0].crs)\n","        \n","        print(\"Total points area:\", len(all_pred_points_df),\" Total duplicates:\", len(dup_pred_polys_df))\n","        return all_pred_points_df, dup_pred_polys_df\n","    else:\n","        print(\"Total points area:\", len(all_pred_points_df),\" Total duplicates:\", len(dup_pred_polys_df))\n","        return all_pred_points_df, dup_pred_polys_df\n","\n","import csv\n","construction_type = \"charcoal_hearth_hill\"\n","cfg_name = 'cfg20200826T2315'\n","pred_poly_folder = os.path.join(\"/content/drive/MyDrive/crane_maryland/polys/\", (cfg_name + \"/\"))\n","\n","# Create an empty geopandas GeoDataFrame\n","all_pred_points_df = gpd.GeoDataFrame()\n","all_pred_points_df['geometry'] = None\n","all_pred_points_df['id'] = None\n","#all_pred_points_df.crs = {'init':'epsg:4326'}\n","all_pred_points_df.crs = ('EPSG:4326')\n","\n","\n","# Create an empty geopandas GeoDataFrame for duplicates\n","dup_pred_polys_df = gpd.GeoDataFrame()\n","dup_pred_polys_df['geometry'] = None\n","dup_pred_polys_df['id'] = None\n","#dup_pred_polys_df.crs = {'init':'epsg:4326'}\n","dup_pred_polys_df.crs = ('EPSG:4326')\n","\n","\n","all_points_outfp = os.path.join(pred_poly_folder, \"4326_000_hearth_prediction_points.shp\")\n","dup_polys_outfp = os.path.join(pred_poly_folder, \"4326_000_duplicate_hearth_prediction_polys.shp\")\n","\n","\n","all_pred_points_df, dup_pred_polys_df = preds_to_points(\"catoctin_1\", pred_poly_folder, all_pred_points_df, dup_pred_polys_df)\n","\n","# Determine the output path for the Shapefile\n","\n","# Write the data into that Shapefile\n","if not all_pred_points_df.empty:    \n","    all_pred_points_df.to_file(all_points_outfp)\n","    print(\"Total points:\", len(all_pred_points_df))\n","if not dup_pred_polys_df.empty:\n","    dup_pred_polys_df.to_file(dup_polys_outfp)\n","    print(\"Total duplicate polys:\", len(dup_pred_polys_df))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["catoctin_1\n","/content/drive/MyDrive/crane_maryland/polys/cfg20200826T2315/4326_catoctin_1_predictions.shp\n","Total points area: 171  Total duplicates: 0\n","Total points: 171\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n","\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n","\n"]}]}]}